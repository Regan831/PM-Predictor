{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and format data for CNN model trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from constants import Constants\n",
    "from grid_definition import GridDefinition\n",
    "from osm_reader import OSMReader\n",
    "import pandas as pd\n",
    "from data_download import DataDownloader\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = Constants()\n",
    "grid_definition = GridDefinition()\n",
    "grid_definition.init()\n",
    "osm_reader = OSMReader()\n",
    "osm_reader.init()\n",
    "\n",
    "GRID_SIZE = constants.getGridSize()\n",
    "\n",
    "topLat = grid_definition.getTopLat()\n",
    "bottomLat = grid_definition.getBottomLat()\n",
    "leftLon = grid_definition.getLeftLon()\n",
    "rightLon = grid_definition.getRightLon()\n",
    "\n",
    "heightInterval = (topLat - bottomLat) / GRID_SIZE\n",
    "widthInterval = (rightLon - leftLon) / GRID_SIZE\n",
    "\n",
    "data_collected = constants.getSelectCollectedDates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180629\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'formatInputData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b914e3094967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     pullCollectedData(start_date) #pull airspeck P data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mformatInputData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pull and format airspeck S data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'formatInputData' is not defined"
     ]
    }
   ],
   "source": [
    "for start_date in data_collected:\n",
    "#     pullCollectedData(start_date) #pull airspeck P data\n",
    "    print(start_date)\n",
    "    formatInputData(start_date) # pull and format airspeck S data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create CSV labels from AirSpeckP data\n",
    "def pullCollectedData(start_date):\n",
    "    end_date = getEndDate(start_date)\n",
    "    sids = ['XXM007', 'XXM008']\n",
    "    \n",
    "    data_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/raw/personal/\"+str(start_date)+\"-\"+str(end_date)+\"/\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        \n",
    "    label_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label\"+str(start_date)+\"/\"\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "    \n",
    "    data_downloader = DataDownloader()\n",
    "#     data_downloader.loadAirSpeckP(start_date, end_date, sids, data_dir) #Only needs to be done once for each date of collected data\n",
    "    pdata = data_downloader.readAirSpeckPCSV(start_date, end_date, data_dir)\n",
    "\n",
    "    PMstrs = ['PM1', 'PM2.5', 'PM10']\n",
    "\n",
    "    for i in range(len(sids)):\n",
    "        labels_sum = np.zeros((3, GRID_SIZE, GRID_SIZE))\n",
    "        labels_count = np.zeros((3, GRID_SIZE, GRID_SIZE))\n",
    "    \n",
    "        dataLength = len(pdata[i])\n",
    "        if (dataLength != 0):\n",
    "            startTime = pdata[i]['Timestamp'][0]\n",
    "            endTime = pdata[i]['Timestamp'][len(pdata[i][\"Timestamp\"]) - 1]\n",
    "            pdata[i]['Timestamp'] = pd.to_datetime(pdata[i]['Timestamp'])\n",
    "            pdata[i]['Timestamp'] = pdata[i]['Timestamp'].dt.round('h')\n",
    "            medianTime = pdata[i]['Timestamp'][int(len(pdata[i][\"Timestamp\"]) / 2) - 1]\n",
    "\n",
    "            for num, lat in enumerate(pdata[i][\"latitude\"]):\n",
    "                lon = pdata[i][\"longitude\"][num]\n",
    "        \n",
    "                row = math.floor((topLat - lat) / heightInterval)\n",
    "                col = math.floor((lon - leftLon) / widthInterval)\n",
    "        \n",
    "                if (row >= 0) & (row < GRID_SIZE) & (col >= 0) & (col < GRID_SIZE): #Because we may have walked outside the area\n",
    "                    for PM in range(3):\n",
    "                        labels_sum[PM][row][col] += pdata[i][PMstrs[PM]][num]\n",
    "                        labels_count[PM][row][col] += 1\n",
    "        \n",
    "            #Take average of all readings within a grid cell\n",
    "            tempLabels = labels_sum / labels_count\n",
    "            nanMask = np.isnan(tempLabels)\n",
    "            tempLabels[nanMask] = -1    \n",
    "    \n",
    "    \n",
    "            #Write PM labels to csv file\n",
    "            for PM in range(3):\n",
    "                filename = label_dir + sids[i] + \"_\" + str(start_date) + \"_\" + PMstrs[PM] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "                with open(filename, 'w') as csvfile:\n",
    "                    csvfile.write(str(startTime) + \"\\n\")\n",
    "                    csvfile.write(str(endTime) + \"\\n\")\n",
    "                    csvfile.write(str(medianTime) + \"\\n\")\n",
    "                    writer = csv.writer(csvfile, lineterminator='\\n')\n",
    "                    writer.writerows(tempLabels[PM])\n",
    "\n",
    "\n",
    "## Create an input CSV from AirSpeckS data\n",
    "def formatInputData(start_date):\n",
    "\n",
    "    uuids = [\"02E5F77764B873DA\",\n",
    "        \"200A7CED9D597407\",\n",
    "        \"E5FD8C55EAA37555\",\n",
    "        \"AA0E63CF5118F98F\",\n",
    "        \"B61241EF668DBC2C\",\n",
    "        \"E786F1568F65C296\" ]\n",
    "\n",
    "    end_date = getEndDate(start_date)\n",
    "    data_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/raw/static/\"+str(start_date)+\"-\"+str(end_date)+\"/\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    label_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label/\"+str(start_date)+\"/\"\n",
    "    train_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/train/\"+str(start_date)+\"/\"\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "        \n",
    "    temperatureSum = 0\n",
    "    temperatureCount = 0\n",
    "    humiditySum = 0\n",
    "    humidityCount = 0\n",
    "    PM = np.zeros((3, 6))\n",
    "\n",
    "    data_downloader = DataDownloader()\n",
    "#     data_downloader.loadAirSpeckS(start_date, end_date, data_dir) #Only needs to be done once for each date of collected data\n",
    "    sdata = data_downloader.readAirSpeckSCSV(start_date, end_date, data_dir)\n",
    "\n",
    "    folder_names = os.listdir(label_dir)\n",
    "\n",
    "    filename = label_dir + folder_names[0]\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        startTime = pd.to_datetime(next(reader)[0])\n",
    "        endTime = pd.to_datetime(next(reader)[0])\n",
    "        medianTime = pd.to_datetime(next(reader)[0])\n",
    "    \n",
    "    for i in range(len(uuids)):\n",
    "        sdata[i]['Timestamp'] = pd.to_datetime(sdata[i]['Timestamp'])\n",
    "        sdata[i] = sdata[i][(sdata[i]['Timestamp'] > startTime) & (sdata[i]['Timestamp'] < endTime)]\n",
    "    \n",
    "        PM[0][i] = np.average(sdata[i]['PM1'])\n",
    "        PM[1][i] = np.average(sdata[i]['PM2.5'])\n",
    "        PM[2][i] = np.average(sdata[i]['PM10'])\n",
    "    \n",
    "        temperatureSum += np.sum(sdata[i]['temperature'])\n",
    "        temperatureCount += len(sdata[i]['temperature'])\n",
    "\n",
    "        humiditySum += np.sum(sdata[i]['humidity'])\n",
    "        humidityCount += len(sdata[i]['humidity'])\n",
    "\n",
    "    averageTemp = temperatureSum / temperatureCount\n",
    "    averageHum = humiditySum / humidityCount\n",
    "       \n",
    "    filename = train_dir + str(start_date) + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        csvfile.write(str(medianTime) + \"\\n\")\n",
    "        csvfile.write(str(averageTemp) + \"\\n\")\n",
    "        csvfile.write(str(averageHum) + \"\\n\")\n",
    "        writer = csv.writer(csvfile, lineterminator='\\n')\n",
    "        writer.writerows(PM)\n",
    "             \n",
    "def getEndDate(start_date):\n",
    "    return start_date + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

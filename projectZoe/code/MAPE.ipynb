{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Average Percentange Error (MAPE) calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to interpolate between six stationary sensor values, perform k-fold cross validation on CNN predictions, and map statistical and CNN prediction results. Mean Average Percentage Error (MAPE) is calculated for interpolation and CNN predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from constants import Constants\n",
    "from grid_definition import GridDefinition\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from osm_reader import OSMReader\n",
    "import folium\n",
    "from data_download import DataDownloader\n",
    "import random\n",
    "\n",
    "import pykrige.kriging_tools as kt\n",
    "from pykrige.uk import UniversalKriging\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from scipy.interpolate import Rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = Constants()\n",
    "gridDefinition = GridDefinition()\n",
    "gridDefinition.init()\n",
    "osm_reader = OSMReader()\n",
    "osm_reader.init()\n",
    "\n",
    "corners = constants.getCorners()\n",
    "staticCoords = constants.getStaticCoords()\n",
    "GRID_SIZE = constants.getGridSize()\n",
    "\n",
    "topLat = gridDefinition.getTopLat()\n",
    "leftLon = gridDefinition.getLeftLon()\n",
    "\n",
    "bottomLat = gridDefinition.getBottomLat()\n",
    "rightLon = gridDefinition.getRightLon()\n",
    "\n",
    "height = topLat - bottomLat\n",
    "width = rightLon - leftLon\n",
    "\n",
    "heightInterval = height / GRID_SIZE\n",
    "widthInterval = width / GRID_SIZE\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "data_downloader = DataDownloader()\n",
    "\n",
    "PMstrs = ['PM1', 'PM2.5', 'PM10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MAPE for Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ryanegan/Documents/diss/projectZoe/data/label/train/20180703/20180703_grid20.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2c625a61ad9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart_date\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_collected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0minterpolate_PM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2584e6aeaf03>\u001b[0m in \u001b[0;36minterpolate_PM\u001b[0;34m(start_date, PM_index, toDelete)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mPM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadStaticData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPM_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/ryanegan/Documents/diss/projectZoe/data/label/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2584e6aeaf03>\u001b[0m in \u001b[0;36mreadStaticData\u001b[0;34m(start_date, PM_index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_grid\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRID_SIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mmedianTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ryanegan/Documents/diss/projectZoe/data/label/train/20180703/20180703_grid20.csv'"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "MAPPING_ON = False\n",
    "DOUBLE_COLLECTION = False\n",
    "interp_strs = [\"linear\", \"smooth\", \"UK\", \"OK\", \"RBF\"]\n",
    "\n",
    "data_collected = constants.getNineteenDates() \n",
    "\n",
    "if (MAPPING_ON):\n",
    "    cells = osm_reader.getGeoCells()\n",
    "\n",
    "for toDelete in range(1):\n",
    "    pm = 1\n",
    "    for i in [0, 1, 2, 3, 4]:\n",
    "        INTERP_TYPE = i\n",
    "        errors = []\n",
    "        for start_date in data_collected:\n",
    "            interpolate_PM(start_date, pm, 0)\n",
    "        \n",
    "        if (errors):\n",
    "            print(str(interp_strs[i]) + \",\" +  str(np.average(errors)))\n",
    "            \n",
    "        print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MAPE for CNN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM2.5, kernel size: 1, learning_rate: 0.005\n",
      "no labels found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/ryanegan/Documents/diss/projectZoe/data/label/train/20180629/XXM007_20180629_PM2.5_grid50.csv' does not exist: b'/Users/ryanegan/Documents/diss/projectZoe/data/label/train/20180629/XXM007_20180629_PM2.5_grid50.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-16a3cc537fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no labels found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mpd_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mPM_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPM_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPM_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/ryanegan/Documents/diss/projectZoe/data/label/train/20180629/XXM007_20180629_PM2.5_grid50.csv' does not exist: b'/Users/ryanegan/Documents/diss/projectZoe/data/label/train/20180629/XXM007_20180629_PM2.5_grid50.csv'"
     ]
    }
   ],
   "source": [
    "data_collected = constants.getNineteenDates() \n",
    "\n",
    "kernel_sizes = [1, 2, 3]\n",
    "learning_rate = 0.005 \n",
    "\n",
    "MAPPING_ON = False\n",
    "\n",
    "if (MAPPING_ON):\n",
    "    cells = osm_reader.getGeoCells()\n",
    "    \n",
    "i = 1\n",
    "\n",
    "for kernel_size in kernel_sizes:\n",
    "    print(PMstrs[i] + \", kernel size: \" + str(kernel_size) +\", learning_rate: \" + str(learning_rate))\n",
    "    errors = []\n",
    "    r2s = []\n",
    "    \n",
    "    for date in data_collected:\n",
    "        ML_dir = '../results/19tune/learning_rate/learning_rate_' +str(learning_rate) + '/kernel_size_' +str(kernel_size) + '/valid_date_'+str(date)+'/'\n",
    "        ML_pred_file = ML_dir + \"PM2.5_prediction.csv\"\n",
    "\n",
    "        pd_df=pd.read_csv(ML_pred_file, sep=' ',header=None)\n",
    "        PM_pred = pd_df.values\n",
    "        label_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label/train/\"+str(date)+\"/\"\n",
    "        sids = ['XXM007', 'XXM008']\n",
    "    \n",
    "        label_file = label_dir + sids[1] + \"_\" + str(date) + \"_\" + PMstrs[i] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "        labels_found = False\n",
    "        \n",
    "        if (os.path.isfile(label_file)):\n",
    "            sid_plot = sids[1]\n",
    "            labels_found = True\n",
    "        else:\n",
    "            label_file = label_dir + sids[0] + \"_\" + str(date) + \"_\" + PMstrs[i] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "            if (os.path.isfile(label_file)):\n",
    "                sid_plot = sids[0]\n",
    "                labels_found = True\n",
    "        if(labels_found):\n",
    "            pd_df=pd.read_csv(label_file, sep=',',header=None, skiprows=3)\n",
    "            labels = pd_df.values\n",
    "        else:\n",
    "            print(\"no labels found\")\n",
    "\n",
    "        pd_df=pd.read_csv(label_file, sep=',',header=None, skiprows=3)\n",
    "        PM_true = pd_df.values\n",
    "        error = calculateError(PM_true, PM_pred)\n",
    "        errors.append(error)\n",
    "        \n",
    "        if (MAPPING_ON):\n",
    "            map_dir = \"/Users/ryanegan/Documents/diss/projectZoe/images/maps/interpolations/CNN/\"+str(date)+\"/\"\n",
    "            maxPM = np.max(PM_pred)\n",
    "            PM_index = 1\n",
    "            pred_map = folium.Map(location=[55.943, -3.19], zoom_start=15,tiles=\"Stamen Toner\")\n",
    "            labelAndPlotPersonalData(map_dir, PM_pred, sid_plot, PM_index, date)\n",
    "        \n",
    "        r2 = calculateR2(PM_true, PM_pred)\n",
    "        r2s.append(r2)\n",
    "    \n",
    "    overallError = np.average(errors)    \n",
    "    print(\" kernel size : , \" + str(kernel_size) + \" , \" + str(overallError))\n",
    "    \n",
    "    ML_train_cost = ML_dir + \"PM2.5_train_cost.csv\"\n",
    "    ML_val_cost = ML_dir + \"PM2.5_valid_cost.csv\"\n",
    "    train_df=pd.read_csv(ML_train_cost, sep=' ',header=None)\n",
    "    valid_df=pd.read_csv(ML_val_cost, sep=' ',header=None)\n",
    "    plt.figure() \n",
    "    valid_df.plot()\n",
    "    ax_val = valid_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for interpolation and machine learning MAPE calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for interpolation and machine learning MAPE calculations\n",
    "def interpolate_PM(start_date, PM_index, toDelete):\n",
    "    PM = []\n",
    "    labels_to_plot = []\n",
    "    x, y, z = readStaticData(start_date, PM_index)\n",
    "    \n",
    "    label_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label/\"+str(start_date)+\"/\"\n",
    "    sids = ['XXM007', 'XXM008']\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    if (DOUBLE_COLLECTION):\n",
    "        index_interp = random.choice((0,1))\n",
    "        index_plot = not index_interp\n",
    "        \n",
    "        sid_interp = sids[index_interp]\n",
    "        sid_plot = sids[index_plot]\n",
    "\n",
    "        plot_filename = label_dir + sid_plot + \"_\" + str(start_date) + \"_\" + PMstrs[PM_index] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "        if (os.path.isfile(plot_filename)):\n",
    "            labels_to_plot.append(sid_plot)\n",
    "            \n",
    "        interp_filename = label_dir + sid_interp + \"_\" + str(start_date) + \"_\" + PMstrs[PM_index] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "        if (os.path.isfile(interp_filename)):\n",
    "            x, y, z = readPersonalData(x, y, z, start_date, sid_interp, PM_index)\n",
    "    \n",
    "    interp_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/data/train/\"+str(start_date)+\"/\"+ PMstrs[PM_index] + \"/\"\n",
    "    if not os.path.exists(interp_dir):\n",
    "        os.makedirs(interp_dir)\n",
    "            \n",
    "    xnew = np.arange(0, GRID_SIZE, 1.0)\n",
    "    ynew = np.arange(0, GRID_SIZE, 1.0)\n",
    "    \n",
    "    if (INTERP_TYPE == 0):\n",
    "        f = interpolate.interp2d(x, y, z, kind='linear')\n",
    "        filename = interp_dir  + str(start_date) + \"_grid\" + str(GRID_SIZE) + \"_interp2D.csv\"\n",
    "        map_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/images/maps/interpolations/interp2d/\"+str(start_date)+\"/\"\n",
    "        PM_pred = f(xnew, ynew)\n",
    "\n",
    "    elif (INTERP_TYPE == 1):\n",
    "        f = interpolate.SmoothBivariateSpline(x, y, z, kx=1, ky=1)\n",
    "        filename = interp_dir + str(start_date) + \"_grid\" + str(GRID_SIZE) + \"_smoothspline.csv\"\n",
    "        map_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/images/maps/interpolations/SmoothBivariate/\"+str(start_date)+\"/\"\n",
    "        PM_pred = f(xnew, ynew)\n",
    "    \n",
    "    elif (INTERP_TYPE == 2):\n",
    "        filename = interp_dir + str(start_date) + \"_grid\" + str(GRID_SIZE) + \"_universalKriging.csv\"\n",
    "        map_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/images/maps/interpolations/UniversalKriging/\"+str(start_date)+\"/\"\n",
    "        UK = UniversalKriging(x, y, z, variogram_model='linear',drift_terms=['regional_linear'])\n",
    "        znew, ss = UK.execute('grid', xnew, ynew)\n",
    "        PM_pred = znew\n",
    "    \n",
    "    elif (INTERP_TYPE == 3):\n",
    "        filename = interp_dir + str(start_date) + \"_grid\" + str(GRID_SIZE) + \"_ordinaryKriging.csv\"\n",
    "        map_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/images/maps/interpolations/OrdinaryKriging/\"+str(start_date)+\"/\"\n",
    "        OK = OrdinaryKriging(x, y, z, variogram_model='linear', verbose=False, enable_plotting=False)\n",
    "        znew, ss = OK.execute('grid', xnew, ynew)\n",
    "        PM_pred = znew\n",
    "        \n",
    "    elif (INTERP_TYPE == 4):\n",
    "        rbfi = Rbf(x, y, z, function='gaussian')\n",
    "        PM_pred = rbfi(xnew, ynew)\n",
    "        filename = interp_dir + str(start_date) + \"_grid\" + str(GRID_SIZE) + \"_rbf.csv\"\n",
    "        map_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/images/maps/interpolations/RBF/\"+str(start_date)+\"/\"\n",
    "\n",
    "        PM_pred = np.zeros((xnew.shape[0], ynew.shape[0]))\n",
    "        for i in range(xnew.shape[0]):\n",
    "            for j in range(ynew.shape[0]):\n",
    "                PM_pred[j,i] = rbfi(xnew[i], ynew[j])\n",
    "\n",
    "    if not os.path.exists(map_dir):\n",
    "        os.makedirs(map_dir)\n",
    "\n",
    "    PM_pred[PM_pred < 0.0] = 0.0 #Shouldn't have negative predictions\n",
    "    maxPM = np.max(PM_pred)\n",
    "\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, lineterminator='\\n')\n",
    "        writer.writerows(PM_pred)\n",
    "\n",
    "    if not DOUBLE_COLLECTION:\n",
    "        filename = label_dir + sids[0] + \"_\" + str(start_date) + \"_\" + PMstrs[1] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "        if (os.path.isfile(filename)):\n",
    "            sid_plot = sids[0]\n",
    "        else:\n",
    "            sid_plot = sids[1]\n",
    "    labelAndPlotPersonalData(map_dir, PM_pred, sid_plot, PM_index, start_date)\n",
    "    \n",
    "def readStaticData(start_date, PM_index):\n",
    "    PM = []\n",
    "\n",
    "    train_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label/train/\"+str(start_date)+\"/\"\n",
    "\n",
    "    filename = train_dir + str(start_date) + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        medianTime = pd.to_datetime(next(reader)[0])\n",
    "        averageTemp = next(reader)[0]\n",
    "        averageHum = next(reader)[0]\n",
    "    \n",
    "        PM.append(next(reader))\n",
    "        PM.append(next(reader))\n",
    "        PM.append(next(reader))\n",
    "    \n",
    "    x = np.zeros(6)\n",
    "    y = np.zeros(6)\n",
    "    z = np.zeros(6)\n",
    "    \n",
    "    for num, coord in enumerate(staticCoords):\n",
    "        col = math.floor((topLat - coord[0]) / heightInterval)\n",
    "        row = math.floor((coord[1] - leftLon) / widthInterval)\n",
    "        x[num] = row\n",
    "        y[num] = col\n",
    "        z[num] = PM[PM_index][num] \n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "def readPersonalData(x_old, y_old, z_old, start_date, sid_interp, PM_index):\n",
    "    labels = []\n",
    "    label_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label/\"+str(start_date)+\"/\"\n",
    "    PMstrs = ['PM1', 'PM2.5', 'PM10']\n",
    "\n",
    "    filename = label_dir + sid_interp + \"_\" + str(start_date) + \"_\" + PMstrs[PM_index] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "    pd_df=pd.read_csv(filename, sep=',',header=None, skiprows=3)\n",
    "    PM_true = pd_df.values\n",
    "    \n",
    "    label_count = (PM_true >= 0).sum() + 1\n",
    "    \n",
    "    x_new = np.zeros(label_count)\n",
    "    y_new = np.zeros(label_count)\n",
    "    z_new = np.zeros(label_count)\n",
    "    \n",
    "    index = 0\n",
    "    for col in range(GRID_SIZE):\n",
    "        for row in range(GRID_SIZE):\n",
    "            PMval = PM_true[row][col]\n",
    "            if (PMval >= 0):\n",
    "                index += 1\n",
    "                x_new[index] = row\n",
    "                y_new[index] = col\n",
    "                z_new[index] = PMval\n",
    "                \n",
    "    x = np.concatenate((x_old, x_new))\n",
    "    y = np.concatenate((y_old, y_new))\n",
    "    z = np.concatenate((z_old, z_new))\n",
    "    return x, y, z\n",
    "    \n",
    "def labelAndPlotPersonalData(map_dir, PM_pred, sid_plot, PM_index, start_date):\n",
    "    label_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/label/\"+str(start_date)+\"/\"\n",
    "    labels = []\n",
    "    filename = label_dir + sid_plot + \"_\" + str(start_date) + \"_\" + PMstrs[PM_index] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "\n",
    "    if (os.path.isfile(filename)):\n",
    "        if (MAPPING_ON):\n",
    "            pred_map = folium.Map(location=[55.943, -3.19], zoom_start=15,tiles=\"Stamen Toner\")\n",
    "            final_map_dir = map_dir + sid_plot\n",
    "            createMap(pred_map, start_date, sid_plot, PM_pred)\n",
    "            pred_map.save(map_dir + str(start_date) + \"_\" + str(sid_plot) + \".html\")\n",
    "            \n",
    "        pd_df=pd.read_csv(filename, sep=',',header=None, skiprows=3)\n",
    "        PM_true = pd_df.values\n",
    "        error = calculateError(PM_true, PM_pred)\n",
    "        errors.append(error)\n",
    "        r2s.append(calculateR2(PM_true, PM_pred))\n",
    "\n",
    "def calculateError(PM_true, PM_pred):\n",
    "    mask = PM_true > 0\n",
    "    PM_mask = PM_true[mask]\n",
    "    PM_diff = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "    errors2 = []\n",
    "\n",
    "    for row in range(GRID_SIZE):\n",
    "        for col in range(GRID_SIZE):\n",
    "            if (PM_true[row][col] > 0):\n",
    "                PM_diff[row][col] = PM_true[row][col] - PM_pred[row][col]\n",
    "                errors2.append(np.abs(PM_diff[row][col]) / PM_true[row][col])\n",
    "            else:\n",
    "                PM_diff[row][col] = 0\n",
    "                PM_true[row][col] = 0\n",
    "                \n",
    "    average_error = np.average(errors2) * 100\n",
    "    return average_error\n",
    "\n",
    "def calculateR2(PM_true, PM_pred):\n",
    "    mean_true = np.average(PM_true)\n",
    "    \n",
    "    PM_SStot = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "    PM_SSres = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "    \n",
    "    for row in range(GRID_SIZE):\n",
    "        for col in range(GRID_SIZE):\n",
    "            if (PM_true[row][col] > 0):\n",
    "                PM_SStot[row][col] = (PM_true[row][col] - mean_true) ** 2\n",
    "                PM_SSres[row][col] = (PM_true[row][col] - PM_pred[row][col]) ** 2\n",
    "                \n",
    "    r2 = 1 - (np.sum(PM_SSres) / np.sum(PM_SStot))\n",
    "    return r2\n",
    "                        \n",
    "def createMap(mapObj, start_date, sid, PM_pred):\n",
    "    end_date = getEndDate(start_date)\n",
    "    data_dir = \"/Users/ryanegan/Documents/diss/projectZoe/data/raw/personal/\"+str(start_date)+\"-\"+str(end_date)+\"/\"\n",
    "    sids = ['XXM007', 'XXM008']\n",
    "    pdata = data_downloader.readAirSpeckPCSV(start_date, end_date, data_dir)\n",
    "    belt_index = sids.index(sid)\n",
    "    \n",
    "    maxPM = np.max(PM_pred)\n",
    "    minPM = np.min(PM_pred)\n",
    "    \n",
    "    ##Add prediction cells\n",
    "    for num, cell in enumerate(cells):\n",
    "        row = int(num / GRID_SIZE)\n",
    "        col = int(num % GRID_SIZE)\n",
    "        PM = PM_pred[row][col]\n",
    "        cell_multi = cell[0][\"geometry\"]\n",
    "        osm_reader.addCellPM(mapObj, cell_multi, PM, maxPM, minPM)\n",
    "            \n",
    "    ##Add validation walk\n",
    "    for j in range(len(pdata[belt_index])):\n",
    "        folium.CircleMarker((pdata[belt_index][\"latitude\"][j], pdata[belt_index][\"longitude\"][j]),\n",
    "                    radius=5,\n",
    "                    color='#000000',\n",
    "                    weight=1.0,\n",
    "                    fill_color=osm_reader.assignColor(pdata[belt_index][\"PM2.5\"][j], maxPM, minPM),\n",
    "                    fill=True,\n",
    "                    fill_opacity=1.0,\n",
    "                   ).add_to(mapObj)\n",
    "\n",
    "def getEndDate(start_date):\n",
    "    return start_date + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import statements**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pykrige.kriging_tools as kt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "import constants\n",
    "import functions5 as functions\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_static_data = functions.load_static_sensors_calibrated_2()\n",
    "all_static_data = functions.transform_to_grid_coordinates(all_static_data)\n",
    "mobile_sensor_data = functions.load_mobile_sensors_2()\n",
    "mobile_sensor_data = functions.transform_to_grid_coordinates(mobile_sensor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute predictions for stationary sensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(pred_value, error_dict, time=None):\n",
    "    if len(error_dict) < 3:\n",
    "        return pred_value\n",
    "    if pred_value + np.mean([y for x,y in error_dict]) < 0:\n",
    "    #if pred_value + max(error_dict, key=lambda item:item[0])[1] < 0:\n",
    "        return 0.0\n",
    "    return pred_value + np.mean([y for x,y in error_dict])\n",
    "    #return pred_value + max(error_dict, key=lambda item:item[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_cell=pd.DataFrame()\n",
    "\n",
    "cells=[(5,12),(0,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_debug=[]\n",
    "\n",
    "mae = []\n",
    "mse = []\n",
    "squares = []\n",
    "\n",
    "start_time = '2018-07-23 00:00:00'\n",
    "start_window = '2018-07-26 13:45:00'\n",
    "end_window = '2018-07-26 14:00:00'\n",
    "\n",
    "number_of_windows = 3\n",
    "window = 15\n",
    "par_grid = functions.create_par(c=0.00002, epsilon=0.001)\n",
    "\n",
    "# Load the 1st dataset pickle file\n",
    "grid_of_errors = pickle.load( open( \"tmp_error_grid/grid_of_errors.p\", \"rb\" ) )\n",
    "# Empty error grid\n",
    "#grid_of_errors = [[[] for x in range(20)] for y in range(20)]\n",
    "\n",
    "timeint_on_first_window = 0\n",
    "tmp_to_test_filename = 'tmp_to_test/with_mobile_data_{}_{}.csv'.format(start_window, number_of_windows)\n",
    "\n",
    "for i in range(1, number_of_windows+1):\n",
    "    end_time = start_window\n",
    "    # treinar sem dados moveis\n",
    "    # testar em dados fixos em vez de móveis\n",
    "    #print(start_window)\n",
    "    #print(end_window)\n",
    "    timeint, par_grid, grid_of_errors = functions.train(all_static_data, mobile_sensor_data, start_time, end_time, par_grid, window, grid_of_errors, timeint_on_first_window)\n",
    "    to_test = functions.test_mobile(par_grid, timeint, mobile_sensor_data, start_window, end_window, 1)\n",
    "    #print(to_test)\n",
    "    \n",
    "    # Calcular o erro numa das colunas do to_test\n",
    "    to_test['error_PM2.5'] = to_test['PM2.5'] - to_test['pred_PM2.5']\n",
    "    to_test['start_window'] = start_window\n",
    "    \n",
    "    # Guardar os erros raw numa coluna pq depois vou descontar os bias na pred_PM2.5\n",
    "    to_test['pred_PM2.5_raw'] = to_test['pred_PM2.5']\n",
    "    \n",
    "    # Guardar o tempo em que aconteceu\n",
    "    to_test['Timestamp'] = start_window\n",
    "    \n",
    "    # Corrigir as previsões com os erros\n",
    "    for index, row in to_test.iterrows():\n",
    "        # aplicar a função correct que aplica a função mean\n",
    "        to_test.at[index, 'pred_PM2.5'] = correct(row['pred_PM2.5'], grid_of_errors[row['lat_grid']][row['long_grid']])\n",
    "        \n",
    "    # Meter os erros na grid\n",
    "    for index, row in to_test.iterrows():\n",
    "        #O uso de index deve ser mudado para o timestamp\n",
    "        grid_of_errors[int(row['lat_grid'])][int(row['long_grid'])].append((row['start_window'], row['error_PM2.5']))\n",
    "        if len(grid_of_errors[int(row['lat_grid'])][int(row['long_grid'])]) > 10:\n",
    "            grid_of_errors[int(row['lat_grid'])][int(row['long_grid'])].pop(0)\n",
    "    \n",
    "    #debug\n",
    "    tmp_debug.append(to_test.loc[(to_test['lat_grid']==0) & (to_test['long_grid']==11)])\n",
    "    \n",
    "    squares.append(to_test.shape[0])\n",
    "    mae.append(mean_absolute_error(to_test['PM2.5'], to_test['pred_PM2.5']))\n",
    "    mse.append(mean_squared_error(to_test['PM2.5'], to_test['pred_PM2.5']))\n",
    "\n",
    "    start_time = end_time\n",
    "    start_window = (datetime.strptime(start_window, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=15)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_window = (datetime.strptime(end_window, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=15)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    timeint_on_first_window = timeint+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_cell_day = pd.concat(tmp_debug, axis = 0)\n",
    "observe_cell = observe_cell.append(observe_cell_day)\n",
    "#grid_of_errors[5][12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0854540400850832\n",
      "1.0715396635748489\n"
     ]
    }
   ],
   "source": [
    "observe_cell['error_applied'] = observe_cell['pred_PM2.5'] - observe_cell['pred_PM2.5_raw']\n",
    "observe_cell[['Timestamp','PM2.5', 'pred_PM2.5_raw', 'pred_PM2.5','error_applied', 'error_PM2.5']]\n",
    "\n",
    "print(mean_absolute_error(observe_cell['PM2.5'], observe_cell['pred_PM2.5']))\n",
    "print(mean_absolute_error(observe_cell['PM2.5'], observe_cell['pred_PM2.5_raw']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

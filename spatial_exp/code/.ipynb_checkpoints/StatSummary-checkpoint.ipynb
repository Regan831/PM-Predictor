{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from constants import Constants\n",
    "from grid_definition import GridDefinition\n",
    "from osm_reader import OSMReader\n",
    "import pandas as pd\n",
    "from data_download import DataDownloader\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_definition = GridDefinition()\n",
    "grid_definition.init()\n",
    "GRID_SIZE = grid_definition.getGridSize()\n",
    "data_downloader = DataDownloader()\n",
    "\n",
    "constants = Constants()   \n",
    "\n",
    "topLat = grid_definition.getTopLat()\n",
    "bottomLat = grid_definition.getBottomLat()\n",
    "leftLon = grid_definition.getLeftLon()\n",
    "rightLon = grid_definition.getRightLon()\n",
    "\n",
    "heightInterval = (topLat - bottomLat) / GRID_SIZE\n",
    "widthInterval = (rightLon - leftLon) / GRID_SIZE\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat Summary\n",
    "Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180629,XXM008,1.549261200926069,0.8053333756793204,2.07128683243385,1.0843567921949937,3.7111253302472935,3.332731599881327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoepetard/miniconda3/envs/msc/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180703,XXM007,0.31255717955581636,0.20074811943623874,0.53115819572709,0.3178825586186953,1.8828444702108094,1.9945941203032849\n",
      "20180704,XXM007,0.22079556879140508,0.38627123098803895,0.5054769690630758,0.5090508371780604,14.860276378813872,10.59005130105607\n",
      "20180704,XXM008,0.30395100345899767,1.1755656255220368,0.48288243233700784,1.6133168270935059,3.7846151227903255,6.750741704693792\n",
      "20180705,XXM008,0.5328163724231882,0.19888461682683925,0.8620284154579116,0.30352203338782935,12.92787572943429,12.957048090125499\n",
      "20180706,XXM007,0.38384899525040134,1.395465771748846,0.6286888576277161,1.7253883174656373,2.6226224444895414,4.790507023943819\n",
      "20180706,XXM008,0.39878087718342087,1.3484584048610477,0.7212802234653178,1.8166332849538793,3.8449064372332087,6.783989226998638\n",
      "20180709,XXM008,0.42135256160296075,0.24828479554408617,0.5607551501963943,0.31829166298401523,1.7135321643069443,2.941044496474512\n",
      "20180710,XXM008,0.18005055482789387,0.16661320988376682,0.2925743127572141,0.24786408417293732,0.8337800369730055,1.3897791669174784\n",
      "20180716,XXM008,0.26144712870767756,0.27664044830036155,0.411768124924431,0.3687654499511135,1.0956708408945428,1.216532144909636\n",
      "20180719,XXM008,0.26575381212215027,0.10578335580109581,0.4354899192617912,0.21617298257309606,1.7051772958823805,1.8739296746461664\n",
      "20180723,XXM008,0.2574316548329731,0.1840689501062875,0.41617398261888683,0.28380876192907606,3.172875416000002,3.859169397495186\n",
      "20180724,XXM008,0.1676006678906258,0.26782864938249584,0.2558364697075842,0.3465486934869778,1.1931420291762793,1.548516866796784\n",
      "20180726,XXM008,0.48340991499249913,0.38788387714192424,0.6790859563108615,0.530414806380804,1.6219554299520453,1.7403294388399573\n",
      "20180730,XXM008,0.19370363772162172,0.2386157652362094,0.30031173372235365,0.3029777991200054,1.7225523137364511,2.857102726690433\n",
      "20180801,XXM008,1.1675587628709896,0.6967785477394093,1.8818515981726456,1.0274077899456584,3.0102441678597742,1.6075229886627789\n",
      "20180802,XXM008,0.14071862311126357,0.23712441545628035,0.2244829184253499,0.30285513818981946,1.599060156856213,1.6574522039585255\n",
      "20180806,XXM008,0.26411207789460617,0.47470019428630117,0.38947217053490907,0.7016975427579639,1.3306205436232366,2.0930084226232077\n",
      "20180807,XXM008,0.27211829212714117,0.28307908251673436,0.3959121210576603,0.40469946217116487,0.9932716326797372,1.5732536545298803\n",
      "20180808,XXM008,0.3219259973495691,0.29498249608971877,0.4959258100050933,0.43581788321536336,1.4855886704926167,1.7032159876340265\n",
      "20180809,XXM008,0.18512044074919773,0.5078558973179566,0.293307157175845,0.642070106120798,0.7830157872298291,1.5737704123116667\n"
     ]
    }
   ],
   "source": [
    "dates = constants.getNineteenDates()\n",
    "#dates = [20180704]\n",
    "\n",
    "for start_date in dates:\n",
    "    #pullInputForAvailableLabel(date)\n",
    "    #formatInputData(start_date)\n",
    "    getMobileStats(start_date)\n",
    "    #getStationaryStats(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullInputForAvailableLabel(start_date):\n",
    "    #start_date = 20180706\n",
    "    end_date = getEndDate(start_date)\n",
    "    #sids = ['XXM007', 'XXM008']\n",
    "    data_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/data/raw/static/\"+str(start_date)+\"-\"+str(end_date)+\"/\"\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    data_downloader = DataDownloader()\n",
    "    #pdata = data_downloader.readAirSpeckSCSV(start_date, end_date, data_dir)\n",
    "    data_downloader.loadAirSpeckS(start_date, end_date, data_dir)\n",
    "    \n",
    "def formatInputData(start_date):\n",
    "\n",
    "    uuids = [\"02E5F77764B873DA\",\n",
    "        \"200A7CED9D597407\",\n",
    "        \"E5FD8C55EAA37555\",\n",
    "        \"AA0E63CF5118F98F\",\n",
    "        \"B61241EF668DBC2C\",\n",
    "        \"E786F1568F65C296\" ]\n",
    "\n",
    "    end_date = getEndDate(start_date)\n",
    "    data_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/data/raw/static/\"+str(start_date)+\"-\"+str(end_date)+\"/\"\n",
    "\n",
    "    temperatureSum = 0\n",
    "    temperatureCount = 0\n",
    "    humiditySum = 0\n",
    "    humidityCount = 0\n",
    "    PM = np.zeros((3, 6))\n",
    "\n",
    "    #data_downloader = DataDownloader()\n",
    "    sdata = data_downloader.readAirSpeckSCSV(start_date, end_date, data_dir)\n",
    "\n",
    "    label_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/data/label/\"+str(start_date)+\"/\"\n",
    "\n",
    "    folder_names = os.listdir(label_dir)\n",
    "\n",
    "    filename = label_dir + folder_names[0]\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        startTime = pd.to_datetime(next(reader)[0])\n",
    "        endTime = pd.to_datetime(next(reader)[0])\n",
    "        medianTime = pd.to_datetime(next(reader)[0])\n",
    "    \n",
    "    for i in range(len(uuids)):\n",
    "        sdata[i]['Timestamp'] = pd.to_datetime(sdata[i]['Timestamp'])\n",
    "        sdata[i] = sdata[i][(sdata[i]['Timestamp'] > startTime) & (sdata[i]['Timestamp'] < endTime)]\n",
    "    #print(sdata[i]['PM1'])\n",
    "    \n",
    "        PM[0][i] = np.average(sdata[i]['PM1'])\n",
    "        PM[1][i] = np.average(sdata[i]['PM2.5'])\n",
    "        PM[2][i] = np.average(sdata[i]['PM10'])\n",
    "        \n",
    "        std_PM1 = np.std(sdata[i]['PM1'])\n",
    "        std_PM25 = np.std(sdata[i]['PM2.5'])\n",
    "        std_PM10 = np.std(sdata[i]['PM10'])\n",
    "        \n",
    "        print(str(start_date) + \",\" + uuids[i] + \",\" + str(PM[0][i]) + \",\" + str(std_PM1)+ \",\" + str(PM[1][i]) + \",\" + str(std_PM25)+ \",\" + str(PM[2][i]) + \",\" + str(std_PM10))\n",
    "\n",
    "    \n",
    "        temperatureSum += np.sum(sdata[i]['temperature'])\n",
    "        temperatureCount += len(sdata[i]['temperature'])\n",
    "        \n",
    "        \n",
    "        intermediateMean = np.average(sdata[i]['humidity'])\n",
    "        intermediateStd = np.std(sdata[i]['humidity'])\n",
    "        #print(str(start_date) + \",\" + uuids[i] + \",\" + str(intermediateMean) + \",\" + str(intermediateStd))\n",
    "        humiditySum += np.sum(sdata[i]['humidity'])\n",
    "        humidityCount += len(sdata[i]['humidity'])\n",
    "    \n",
    "def getMobileStats(start_date):\n",
    "    end_date = getEndDate(start_date)\n",
    "    #end_date = start_date + 1\n",
    "    data_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/data/raw/personal/\"+str(start_date)+\"-\"+str(end_date)+\"/\"\n",
    "    sids = ['XXM007', 'XXM008']\n",
    "    \n",
    "    #if not os.path.exists(data_dir):\n",
    "    #    os.makedirs(data_dir)\n",
    "    \n",
    "    #data_downloader = DataDownloader()\n",
    "    #data_downloader.loadAirSpeckP(start_date, end_date, sids, data_dir)\n",
    "    pdata = data_downloader.readAirSpeckPCSV(start_date, end_date, data_dir)\n",
    "\n",
    "    label_dir = \"/Users/zoepetard/Google Drive/Edinburgh/MscProj/FillingTheGaps/data/label/\"+str(start_date)+\"/\"\n",
    "\n",
    "    #print(GRID_SIZE)\n",
    "\n",
    "    #if not os.path.exists(label_dir):\n",
    "    #    os.makedirs(label_dir)\n",
    "\n",
    "    #labels = []\n",
    "    \n",
    "    #PM1 = []\n",
    "\n",
    "    \n",
    "    PMstrs = ['PM1', 'PM2.5', 'PM10']\n",
    "\n",
    "    for i in range(len(sids)):\n",
    "        labels_sum = np.zeros((3, GRID_SIZE, GRID_SIZE))\n",
    "        labels_count = np.zeros((3, GRID_SIZE, GRID_SIZE))\n",
    "    \n",
    "        dataLength = len(pdata[i])\n",
    "        labels = np.zeros((3, dataLength))\n",
    "        \n",
    "        if (dataLength != 0):\n",
    "    #print(dataLength)\n",
    "            startTime = pdata[i]['Timestamp'][0]\n",
    "            endTime = pdata[i]['Timestamp'][len(pdata[i][\"Timestamp\"]) - 1]\n",
    "            #print(startTime)\n",
    "            #print(endTime)\n",
    "            pdata[i]['Timestamp'] = pd.to_datetime(pdata[i]['Timestamp'])\n",
    "            pdata[i]['Timestamp'] = pdata[i]['Timestamp'].dt.round('h')\n",
    "            medianTime = pdata[i]['Timestamp'][int(len(pdata[i][\"Timestamp\"]) / 2) - 1]\n",
    "            #print(medianTime)\n",
    "\n",
    "            for num, lat in enumerate(pdata[i][\"latitude\"]):\n",
    "                lon = pdata[i][\"longitude\"][num]\n",
    "        \n",
    "                row = math.floor((topLat - lat) / heightInterval)\n",
    "                col = math.floor((lon - leftLon) / widthInterval)\n",
    "        \n",
    "                if (row >= 0) & (row < GRID_SIZE) & (col >= 0) & (col < GRID_SIZE): #Because we may have walked outside the area\n",
    "                    for PM in range(3):\n",
    "                        data_point = pdata[i][PMstrs[PM]][num]\n",
    "                        labels[PM][num] = data_point\n",
    "                        labels_sum[PM][row][col] += data_point\n",
    "                        labels_count[PM][row][col] += 1\n",
    "        \n",
    "    #Take average of all readings within a grid cell\n",
    "            #for PM in range(3):\n",
    "        \n",
    "            #print(labels)\n",
    "            mean_PM1 = np.average(labels[0])\n",
    "            std_PM1 = np.std(labels[0])\n",
    "            mean_PM25 = np.average(labels[1])\n",
    "            std_PM25 = np.std(labels[1])\n",
    "            mean_PM10 = np.average(labels[2])\n",
    "            std_PM10 = np.std(labels[2])\n",
    "                \n",
    "            print(str(start_date) + \",\" + sids[i] + \",\" + str(mean_PM1) + \",\" + str(std_PM1)+ \",\" + str(mean_PM25) + \",\" + str(std_PM25)+ \",\" + str(mean_PM10) + \",\" + str(std_PM10))\n",
    "            #print(len(labels[0]))\n",
    "            #print(len(labels[1]))\n",
    "            #print(len(labels[2]))\n",
    "                \n",
    "            #sum_of_walk = np.sum(labels)\n",
    "            #print(\"sum of labels: \" + str(sum_of_walk))\n",
    "            #mean_PM1 = np.average(labels[0])\n",
    "            #print(\"mean of labels: \" + str(mean_of_walk))\n",
    "            #std_PM1 = np.std(labels[0])\n",
    "            #print(\"std of labels: \" + str(std_of_walk))\n",
    "            \n",
    "            #print(labels)\n",
    "            #print(str(start_date) + \",\" + sids[i] + \",\" + str(mean_PM1) + \",\" + str(std_PM1))\n",
    "            \n",
    "            tempLabels = labels_sum / labels_count\n",
    "            nanMask = np.isnan(tempLabels)\n",
    "            tempLabels[nanMask] = -1    \n",
    "    #labels.append(tempLabels)\n",
    "    \n",
    "    #Write PM labels to csv file\n",
    "            for PM in range(3):\n",
    "                filename = label_dir + sids[i] + \"_\" + str(start_date) + \"_\" + PMstrs[PM] + \"_grid\" + str(GRID_SIZE) + \".csv\"\n",
    "                with open(filename, 'w') as csvfile:\n",
    "                    csvfile.write(str(startTime) + \"\\n\")\n",
    "                    csvfile.write(str(endTime) + \"\\n\")\n",
    "                    csvfile.write(str(medianTime) + \"\\n\")\n",
    "                    writer = csv.writer(csvfile, lineterminator='\\n')\n",
    "                    writer.writerows(tempLabels[PM])\n",
    "                    \n",
    "def getStationaryStats(start_date):\n",
    "    end_date = getEndDate(start_date)\n",
    "\n",
    "    \n",
    "                    \n",
    "def getEndDate(start_date):\n",
    "    if (start_date == 20180731):\n",
    "        end_date = 20180801\n",
    "    else:\n",
    "        end_date = start_date + 1\n",
    "    return end_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
